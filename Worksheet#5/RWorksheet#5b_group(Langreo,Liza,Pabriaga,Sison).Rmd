---
title: '"RWorksheet#5b_group(Langreo,Liza,Pabriaga,Sison)'
author: "John Martin S. Pabriaga"
date: "2024-12-02"
output: pdf_document
---
```{r}
library(rvest)      
library(dplyr)      
library(stringr)    
```
```{r}
# Define product links and product names
product_links <- c(
  "https://www.amazon.com/Oxfords-Lace-Up-Lightweight-Walking-Sneakers/dp/B0DDTSDX32/ref=sr_1_1",
  "https://www.amazon.com/Skechers-Summits-Range-Loafer-Charcoal/dp/B0BJ2769FH/ref=sr_1_2",
  "https://www.amazon.com/Under-Armour-Charged-Surge-Running/dp/B0BZXT1RHW/ref=sr_1_3",
  "https://www.amazon.com/Under-Armour-Charged-Assert-Running/dp/B0BZXP99N5/ref=sr_1_4",
  "https://www.amazon.com/Bruno-Marc-Sneakers-Lightweight-Grand-01/dp/B07ZLM669B/ref=sr_1_5",
  "https://www.amazon.com/adidas-Womens-Court-Sneaker-White/dp/B0C2JZ4K9V/ref=sr_1_6",
  "https://www.amazon.com/adidas-Daily-Sneaker-Black-White/dp/B0CKMB4SSD/ref=sr_1_7",
  "https://www.amazon.com/adidas-X_PLRPATH-Sneaker-Black-White/dp/B0BZ5TMVYK/ref=sr_1_8",
  "https://www.amazon.com/adidas-Racer-Adapt-Sneaker-White/dp/B0CKM9P7FN/ref=sr_1_9",
  "https://www.amazon.com/Under-Armour-Grade-School-Running/dp/B0BZXLBCJ8/ref=sr_1_10"
)

product_names <- c(
   "Mens Oxfords Lace-Up Lightweight Casual Walking Shoes Dress Shoes Fashion Sneakers Walking Shoes",
  "Skechers Men's Summits High Range Hands Free Slip-in",
  "Under Armour Men's Charged Surge 4 Sneaker",
  "Under Armour Men's Charged Assert 10",
  "Bruno Marc Men's KnitFlex Breeze Mesh Sneakers Oxfords Lace-Up Lightweight Casual Walking Shoes",
  "adidas Women's Vl Court 3.0",
  "adidas Men's Daily 4.0 Shoes",
  "adidas Men's X_PLR Path Sneaker",
  "adidas Men's Lite Racer Adapt 7.0 Sneaker",
  "Under Armour Boys' Grade School Surge 4 Running Shoe"
)

category <- "Shoes"
```


```{r}
# Initialize an empty dataframe
all_reviews <- data.frame()
```


```{r}
# Loop through each product
for (i in seq_along(product_links)) {
  url <- product_links[i]
  product_name <- product_names[i]
  
  # Variable to store all reviews for the current product
  reviewer_names <- character()
  review_dates <- character()
  review_titles <- character()
  review_comments <- character()
  verified_purchases <- character()
  star_ratings <- numeric()
  
  # Loop to scrape multiple pages (each page has 10 reviews)
  page_num <- 1
  while(length(reviewer_names) < 20) {
    # Modify the URL to include the page number for pagination
    paginated_url <- paste0(url, "?pageNumber=", page_num)
    
    try({
      webpage <- read_html(paginated_url)
      
      # Extract review sections
      reviews <- webpage %>%
        html_nodes(".review")
      
      # Extract reviewer names
      reviewer_names_page <- reviews %>%
        html_nodes(".a-profile-name") %>%
        html_text(trim = TRUE)
      
      # Extract review dates
      review_dates_page <- reviews %>%
        html_nodes(".review-date") %>%
        html_text(trim = TRUE)
      
      # Extract review titles
      review_titles_page <- reviews %>%
        html_nodes(".review-title span") %>%
        html_text(trim = TRUE)
      
      # Extract review comments
      review_comments_page <- reviews %>%
        html_nodes(".review-text-content span") %>%
        html_text(trim = TRUE)
      
      # Extract verified purchase labels
      verified_purchases_page <- reviews %>%
        html_nodes(".review-vp-label") %>%
        html_text(trim = TRUE)
      
      # Extract star ratings
      star_ratings_page <- reviews %>%
        html_nodes(".a-icon-alt") %>%
        html_text(trim = TRUE) %>%
        str_extract("\\d\\.\\d") %>%  # Extract the numeric rating
        as.numeric()
      
      # Append the data
      reviewer_names <- c(reviewer_names, reviewer_names_page)
      review_dates <- c(review_dates, review_dates_page)
      review_titles <- c(review_titles, review_titles_page)
      review_comments <- c(review_comments, review_comments_page)
      verified_purchases <- c(verified_purchases, verified_purchases_page)
      star_ratings <- c(star_ratings, star_ratings_page)
      
      # Increment page number to move to the next page
      page_num <- page_num + 1
    }, silent = TRUE)
    
    # If we've collected enough reviews, break out of the loop
    if(length(reviewer_names) >= 20) {
      break
    }
  }
  
  # Limit to the first 20 reviews
  max_reviews <- min(20, length(reviewer_names))
  reviewer_names <- reviewer_names[1:max_reviews]
  review_dates <- review_dates[1:max_reviews]
  review_titles <- review_titles[1:max_reviews]
  review_comments <- review_comments[1:max_reviews]
  verified_purchases <- verified_purchases[1:max_reviews]
  star_ratings <- star_ratings[1:max_reviews]
  
  # Create a dataframe for this product
  review_data <- data.frame(
    Category = rep(category, max_reviews),
    ProductName = rep(product_name, max_reviews),
    Reviewer = reviewer_names,
    Date = review_dates,
    Title = review_titles,
    Comment = review_comments,
    StarRating = star_ratings,
    VerifiedPurchase = verified_purchases,
    stringsAsFactors = FALSE
  )
  
  # Append to the main dataframe
  all_reviews <- bind_rows(all_reviews, review_data)
}

# Print the result
print(all_reviews)
```
```{r}
# Save the reviews to a CSV file
write.csv(all_reviews, "Shoes_Reviews.csv", row.names = FALSE)
```