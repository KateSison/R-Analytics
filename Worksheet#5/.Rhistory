options(repos = c(CRAN = "https://cloud.r-project.org/"))
# Install and load the rvest and polite packages
#if (!requireNamespace("rvest", quietly = TRUE)) {
install.packages("rvest")
#}
library(rvest)
library(polite)
# Read the HTML file
url <- "https://www.amazon.com/s?k=amazon+men%27s+shoes&language=en_US&adgrpid=142537954933&hvadid=673511619493&hvdev=c&hvlocphy=20838&hvnetw=g&hvqmt=e&hvrand=3648587730247776380&hvtargid=kwd-298699618939&hydadcr=3879_13369274&tag=phtxtgostdde-20&ref=pd_sl_7ot3671bin_e"
Ses <- bow(url, user_agent = "Student's Demo Educational")
Ses
Page <- scrape(Ses)
# Find all div elements with the specified class
div <- html_nodes(Page, 'div.sg-col-4-of-24.sg-col-4-of-12.s-result-item.s-asin.sg-col-4-of-16.sg-col.s-widget-spacing-small.sg-col-4-of-20')
# Create empty vectors to store data
links <- character()
img_srcs <- character()
titles <- character()
prices <- character()
ratings <- character()
reviews <- character()  # Create a vector for reviews count
max_prod <- 20
# Limit the loop to only collect data for the first 20 products
for (i in 1:min(length(div), max_prod)) {
div_e <- div[i]
# Find the a element with class="a-link-normal s-no-outline" and get the link
a_element <- html_node(div_e, 'a.a-link-normal.s-no-outline')
link <- ifelse(!is.na(a_element), paste0("https://amazon.com", html_attr(a_element, "href")), '')
# Find the img element with class="s-image" and get the link
img <- html_node(div_e, 'img.s-image')
img_src <- ifelse(!is.na(img), html_attr(img , "src"), '')
# Find the span element with class="a-size-base-plus a-color-base a-text-normal" and get the title
title_e <- html_node(div_e, 'span.a-size-base-plus.a-color-base.a-text-normal')
title <- ifelse(!is.na(title_e), html_text(title_e), '')
# Find the span element with class="a-price-whole" and get the price
price_e <- html_node(div_e, 'span.a-price-whole')
price <- ifelse(!is.na(price_e), html_text(price_e), '')
# Find the span element with class="a-icon-alt" and get the ratings
rating_e <- html_node(div_e, 'span.a-icon-alt')
rating <- ifelse(!is.na(rating_e), html_text(rating_e), '')
# Find the span element containing review count (this can vary)
review_count_e <- html_node(div_e, 'span.a-size-base')
review_count <- ifelse(!is.na(review_count_e), html_text(review_count_e), '0')  # Default to 0 if no review count
# Append data to vectors
links <- c(links, link)
img_srcs <- c(img_srcs, img_src)
titles <- c(titles, title)
prices <- c(prices, price)
ratings <- c(ratings, rating)
reviews <- c(reviews, review_count)  # Add review count here
}
# Create a data frame with the scraped data
prod_df <- data.frame(
Links = links,
Images = img_srcs,
Title = titles,
Price = prices,
Rating = ratings,
Reviews = reviews  # Include review count column
)
# Write the data to a CSV file
write.csv(prod_df, "Shoesable.csv", row.names = FALSE)
options(repos = c(CRAN = "https://cloud.r-project.org/"))
# Install and load the rvest and polite packages
#if (!requireNamespace("rvest", quietly = TRUE)) {
install.packages("rvest")
#}
library(rvest)
library(polite)
# Read the HTML file
url <- "https://www.amazon.com/s?k=amazon+men%27s+shoes&language=en_US&adgrpid=142537954933&hvadid=673511619493&hvdev=c&hvlocphy=20838&hvnetw=g&hvqmt=e&hvrand=3648587730247776380&hvtargid=kwd-298699618939&hydadcr=3879_13369274&tag=phtxtgostdde-20&ref=pd_sl_7ot3671bin_e"
Ses <- bow(url, user_agent = "Student's Demo Educational")
Ses
Page <- scrape(Ses)
# Find all div elements with the specified class
div <- html_nodes(Page, 'div.sg-col-4-of-24.sg-col-4-of-12.s-result-item.s-asin.sg-col-4-of-16.sg-col.s-widget-spacing-small.sg-col-4-of-20')
# Create empty vectors to store data
links <- character()
img_srcs <- character()
titles <- character()
prices <- character()
ratings <- character()
reviews <- character()  # Create a vector for reviews count
max_prod <- 20
# Limit the loop to only collect data for the first 20 products
for (i in 1:min(length(div), max_prod)) {
div_e <- div[i]
# Find the a element with class="a-link-normal s-no-outline" and get the link
a_element <- html_node(div_e, 'a.a-link-normal.s-no-outline')
link <- ifelse(!is.na(a_element), paste0("https://amazon.com", html_attr(a_element, "href")), '')
# Find the img element with class="s-image" and get the link
img <- html_node(div_e, 'img.s-image')
img_src <- ifelse(!is.na(img), html_attr(img , "src"), '')
# Find the span element with class="a-size-base-plus a-color-base a-text-normal" and get the title
title_e <- html_node(div_e, 'span.a-size-base-plus.a-color-base.a-text-normal')
title <- ifelse(!is.na(title_e), html_text(title_e), '')
# Find the span element with class="a-price-whole" and get the price
price_e <- html_node(div_e, 'span.a-price-whole')
price <- ifelse(!is.na(price_e), html_text(price_e), '')
# Find the span element with class="a-icon-alt" and get the ratings
rating_e <- html_node(div_e, 'span.a-icon-alt')
rating <- ifelse(!is.na(rating_e), html_text(rating_e), '')
# Find the span element containing review count (this can vary)
review_count_e <- html_node(div_e, 'span.a-size-base')
review_count <- ifelse(!is.na(review_count_e), html_text(review_count_e), '0')  # Default to 0 if no review count
# Append data to vectors
links <- c(links, link)
img_srcs <- c(img_srcs, img_src)
titles <- c(titles, title)
prices <- c(prices, price)
ratings <- c(ratings, rating)
reviews <- c(reviews, review_count)  # Add review count here
}
# Create a data frame with the scraped data
prod_df <- data.frame(
Links = links,
Images = img_srcs,
Title = titles,
Price = prices,
Rating = ratings,
Reviews = reviews  # Include review count column
)
# Write the data to a CSV file
write.csv(prod_df, "Shoesable.csv", row.names = FALSE)
options(repos = c(CRAN = "https://cloud.r-project.org/"))
# Install and load the rvest and polite packages
#if (!requireNamespace("rvest", quietly = TRUE)) {
install.packages("rvest")
#}
library(rvest)
library(polite)
# Read the HTML file
url <- "https://www.amazon.com/bag/s?k=bag"
Ses <- bow(url, user_agent = "Student's Demo Educational")
Ses
Page <- scrape(Ses)
